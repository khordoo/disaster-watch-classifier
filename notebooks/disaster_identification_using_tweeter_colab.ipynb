{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "disaster_identification_using_tweeter_remove_unrelated.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmgwuQUFyyBe",
        "colab_type": "text"
      },
      "source": [
        "# Identifying and categorizing the disaster-related tweets\n",
        "Semantic, temporal and spatial context , using natural language processing ,Deep Learning and spatial analysis\n",
        "\n",
        "\n",
        "## 1. Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdD9XAs2yyBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "!pip3 install tensorflow-gpu==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "from sklearn.base import TransformerMixin ,BaseEstimator\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential ,model_from_json\n",
        "from tensorflow.keras.layers import Embedding,Dense,Dropout ,GlobalMaxPool1D\n",
        "from IPython.display import clear_output\n",
        "from google.colab import  files\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nudx66pazEmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('combined.csv'):\n",
        "   dataset=files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeelkjKwyyBj",
        "colab_type": "text"
      },
      "source": [
        "## 2. Data Loading\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3etvRU5yyBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class DatasetExtractor(BaseEstimator,TransformerMixin):\n",
        "    \"\"\"Extractor class that loads multiple Tweeter files in csv format.\"\"\"\n",
        "    \n",
        "    COMBINDED_DATASET='combined.csv'\n",
        "    \n",
        "    def transform(self,X,y=None):\n",
        "        return self.hot_load()\n",
        "    \n",
        "    def hot_load(self):\n",
        "        \"\"\"Loads the pre-combined file if exists otherwise load all the files\"\"\"\n",
        "        combined_file_path='combined.csv'\n",
        "        if os.path.isfile(combined_file_path):\n",
        "            print('File Exists.Reloaded.')\n",
        "            return pd.read_csv(combined_file_path, index_col=0)\n",
        "        print('Loading Files..')\n",
        "        combined_dataset=load_data()\n",
        "        combined_dataset.to_csv(combined_file_path)\n",
        "        return combined_dataset\n",
        "    \n",
        "    def load_data(self):\n",
        "        \"\"\"Loads multiple disaster related tweet file and returns a Single Pandas data frame\"\"\"    \n",
        "        combined_dataset=pd.DataFrame()\n",
        "        for file_name in os.listdir(path=DATA_DIRECTORY):\n",
        "            category=extract_category_name(file_name)\n",
        "            df=pd.read_csv(f'{file_name}')\n",
        "            df['category']= category    \n",
        "            combined_dataset=combined_dataset.append(df,ignore_index = True)\n",
        "        return  combined_dataset  \n",
        "    \n",
        "    def extract_category_name(self,file_name):\n",
        "        \"\"\"Helper method that extracts the Disaster Category from the file name\"\"\"\n",
        "        category=file_name.split('.')[0]\n",
        "        if '_' in category:\n",
        "            category=category.split('_')[0]\n",
        "        return category "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDVupu6qyyBm",
        "colab_type": "text"
      },
      "source": [
        "## 3. Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwhMKFksyyBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DatasetCleaner(BaseEstimator,TransformerMixin):\n",
        "    \"\"\"Removes Redundent features and rows with missing values\"\"\"\n",
        "    def transform(self,X,y=None):\n",
        "        columns=X.columns.tolist()\n",
        "        X.columns=[column.strip() for column in columns]\n",
        "        X=X.drop('tweet id',axis=1)\n",
        "        X=X.dropna()\n",
        "        X['tweet']=X['tweet'].str.replace('@', '')\n",
        "        X['tweet']=X['tweet'].str.replace('#', '')\n",
        "        X['tweet']=X['tweet'].str.replace('http\\S+', '',regex=True)\n",
        "        X['tweet']=X['tweet'].str.strip()\n",
        "        X['tweet']=X['tweet'].str.lower()        \n",
        "        return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTT8FZSuJ67c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NamedEntityRemover(BaseEstimator,TransformerMixin):\n",
        "  \"\"\"Removes Named Entities from the data.\n",
        "     This prevents associating the places with disasters.\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    self.nlp = spacy.load('en')\n",
        "    \n",
        "  def transform(self,X,y=None):\n",
        "      nlp = spacy.load('en')\n",
        "      X['tweet']=X['tweet'].apply(lambda x : self._remove_named_entities(x))\n",
        "      return X\n",
        "  def _remove_named_entities(self,x):\n",
        "      x=x.title()\n",
        "      doc = nlp(x)\n",
        "      for ent in doc.ents:\n",
        "        x=x.replace(str(ent[0]) ,'')\n",
        "      return x.lower()\n",
        "# df =pd.DataFrame({'tweet':['this is Iran canada and france', 'alos ther is for germany']})\n",
        "# NamedEntityRemover().transform(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4BqQgxsyyBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DistributionValidSampler(BaseEstimator,TransformerMixin):\n",
        "    \"\"\"Samples the (related and random ) tweets with equal proportion\"\"\"\n",
        "    def __init__(self,unrelated_size=None ,ignore_unrelated_proportion=True):\n",
        "        self._unrelated_size=unrelated_size\n",
        "        self._ignore_unrelated_proportion=ignore_unrelated_proportion\n",
        "\n",
        "        \n",
        "    def transform(self,X,y=None):\n",
        "        #Shuffle tweets\n",
        "        X_=X.sample(frac=1).reset_index(drop=True)\n",
        "        \n",
        "        X_=self._label_categories(X_)  \n",
        "        related,unrelated =self._equal_split(X_)\n",
        "        X_=self._merge(related,unrelated)\n",
        "        X_=X_.drop('category',axis=1)       \n",
        "        return X_\n",
        "    \n",
        "    def _label_categories(self,X):\n",
        "        \"\"\"Assings the category name to on-topic tweets and unrelated to off-topic tweets in \n",
        "         each category\n",
        "        \"\"\"\n",
        "        \n",
        "        if self._ignore_unrelated_proportion:\n",
        "            X['label']=X.apply(lambda row: row['category'] if 'on-topic' in row['label'] else 'unrelated',axis=1 ) \n",
        "        else:\n",
        "            X['label']=X.apply(lambda row: row['category'] if 'on-topic' in row['label'] else 'unrelated_'+row['category'],axis=1 )  \n",
        "        return X\n",
        "    \n",
        "    def _equal_split(self,X):\n",
        "        \"\"\"Splits the dataseta into related and unrelated tweets.\n",
        "          This ensures that the number of unrelated tweets are not too high and \n",
        "          is in reasonable range.\n",
        "        \"\"\"\n",
        "        related=X[X['label'].str.contains('unrelated')==False]\n",
        "        unrelated=X[X['label'].str.contains('unrelated')]\n",
        "        ave_tweets=self._average_tweet_per_category(X)\n",
        "        unrelated=self._slice(unrelated,size=self._unrelated_size ,ave_size=ave_tweets)\n",
        "        return related,unrelated\n",
        "    \n",
        "    def _merge(self,X1,X2):\n",
        "        \"\"\"Merges the dataframes toghether\"\"\"\n",
        "        X=pd.DataFrame()\n",
        "        X=X.append(X1)\n",
        "        X=X.append(X2)\n",
        "        return X\n",
        "    \n",
        "    def _slice(self,X, size ,ave_size):\n",
        "        \"\"\"Extracts a subset of rows from a dataframe\"\"\"\n",
        "        if size is None:\n",
        "            size =ave_size\n",
        "        if size < X.shape[0]:\n",
        "            return X[:size]\n",
        "        return X    \n",
        "    \n",
        "    def _average_tweet_per_category(self,X):\n",
        "        \"\"\"Calculate the average number of tweets across all tweet categories\"\"\"\n",
        "        category_values=pd.DataFrame(X['label'].value_counts())\n",
        "        category_values=category_values.drop('unrelated',axis=0)\n",
        "        return int(category_values['label'].mean())\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOeSsPzbyyBr",
        "colab_type": "text"
      },
      "source": [
        "### 4. Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzsGvjr4yyBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextTokenizer(BaseEstimator,TransformerMixin):\n",
        "    \n",
        "    def __init__(self,pad_sequences,num_words=10000,max_length=100,max_pad_length=100 ):\n",
        "        self._num_words=num_words\n",
        "        self.max_length=max_length\n",
        "        self._tokenizer=None\n",
        "        self._pad_sequences=pad_sequences\n",
        "        self._max_pad_length=max_pad_length\n",
        "        self.vocab_size=None\n",
        "        self.tokenizer=None\n",
        "        \n",
        "    def transform(self,X,y=None):\n",
        "        self.tokenizer,self.vocab_size=self._get_tokenizer(X['tweet'])\n",
        "        X['tweet_encoded']=self.tokenizer.texts_to_sequences(X['tweet'])\n",
        "        X['tweet_encoded']= X['tweet_encoded'].apply(lambda x: self._pad_sequences([x],maxlen=self._max_pad_length ,padding='post')[0])\n",
        "        \n",
        "        return X\n",
        "    def _get_tokenizer(self,X):\n",
        "        tokenizer=tf.keras.preprocessing.text.Tokenizer(num_words=self._num_words)\n",
        "        tokenizer.fit_on_texts(X)\n",
        "        vocab_size=len(tokenizer.word_index)+1\n",
        "        return tokenizer,vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyOi2VZryyBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LabelOneHotEncoder(BaseEstimator,TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.label_encoder=None\n",
        "        self.one_hot_encoder=None\n",
        "        \n",
        "    def transform(self,X,y=None):\n",
        "        self.label_encoder=LabelEncoder().fit(X['label'])\n",
        "        self.one_hot_encoder=to_categorical\n",
        "        num_classes=len(set(X['label']))\n",
        "        X['label_encoded']= self.label_encoder.transform(X['label'].values)\n",
        "        X['label_one_hot']= X['label_encoded'].apply(lambda x: self.one_hot_encoder([x],num_classes=num_classes)[0])   \n",
        "        \n",
        "        return X\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QygVpjcyyBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PassThroughTransformer(BaseEstimator,TransformerMixin):\n",
        "    \"\"\"Pass Through Trasformer to by pass the sklean pipleline limitation \"\"\"\n",
        "    def transform(self,X,y=None):\n",
        "        return X\n",
        "    def fit(self,X,y=None):\n",
        "        return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "S1mAD2ptyyB0",
        "colab_type": "code",
        "outputId": "b338b2c2-0664-4d4d-cf98-d4c80c38f773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "pad_sequence=tf.keras.preprocessing.sequence.pad_sequences\n",
        "\n",
        "\n",
        "pipeline =Pipeline(steps=[\n",
        "    ('extractor',DatasetExtractor()),\n",
        "    ('cleaner',DatasetCleaner()),\n",
        "#     ('ne-remover',NamedEntityRemover()),\n",
        "    ('distribution-validator',DistributionValidSampler(unrelated_size=None ,ignore_unrelated_proportion=True)),\n",
        "    ('tokenizer',TextTokenizer(pad_sequence)),\n",
        "    ('one-hot-encoder',LabelOneHotEncoder()),\n",
        "    ('pass-through',PassThroughTransformer()),\n",
        "    \n",
        "])\n",
        "cleaned=pipeline.transform(None)\n",
        "cleaned.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Exists.Reloaded.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet_encoded</th>\n",
              "      <th>label_encoded</th>\n",
              "      <th>label_one_hot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rt allybrooke: so sorry for the explosion in w...</td>\n",
              "      <td>explosion</td>\n",
              "      <td>[2, 4659, 42, 749, 8, 1, 14, 3, 107, 19, 20, 1...</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>.thinkprogress: tea party congressman using bo...</td>\n",
              "      <td>bombing</td>\n",
              "      <td>[2472, 2347, 705, 9209, 1250, 149, 4, 7811, 82...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>rt youranonnews: breaking: west fertilizer pla...</td>\n",
              "      <td>explosion</td>\n",
              "      <td>[2, 348, 117, 46, 48, 38, 47, 5030, 8, 3514, 4...</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>the bruins game better not get cancelled. we a...</td>\n",
              "      <td>bombing</td>\n",
              "      <td>[1, 1693, 613, 443, 65, 93, 899, 41, 27, 124, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>have seen some young people in reddeer tweetin...</td>\n",
              "      <td>floods</td>\n",
              "      <td>[39, 432, 141, 1276, 31, 3, 5448, 1380, 474, 5...</td>\n",
              "      <td>3</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                tweet      label  \\\n",
              "0   rt allybrooke: so sorry for the explosion in w...  explosion   \n",
              "2   .thinkprogress: tea party congressman using bo...    bombing   \n",
              "7   rt youranonnews: breaking: west fertilizer pla...  explosion   \n",
              "9   the bruins game better not get cancelled. we a...    bombing   \n",
              "10  have seen some young people in reddeer tweetin...     floods   \n",
              "\n",
              "                                        tweet_encoded  label_encoded  \\\n",
              "0   [2, 4659, 42, 749, 8, 1, 14, 3, 107, 19, 20, 1...              2   \n",
              "2   [2472, 2347, 705, 9209, 1250, 149, 4, 7811, 82...              0   \n",
              "7   [2, 348, 117, 46, 48, 38, 47, 5030, 8, 3514, 4...              2   \n",
              "9   [1, 1693, 613, 443, 65, 93, 899, 41, 27, 124, ...              0   \n",
              "10  [39, 432, 141, 1276, 31, 3, 5448, 1380, 474, 5...              3   \n",
              "\n",
              "                          label_one_hot  \n",
              "0   [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n",
              "2   [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
              "7   [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n",
              "9   [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
              "10  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av3JRhv_yyB4",
        "colab_type": "text"
      },
      "source": [
        "## 5. Train Validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN8o5kIayyB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,y_train,y_test =train_test_split(cleaned['tweet_encoded'],cleaned['label_one_hot'],test_size=0.3,stratify=cleaned['label_encoded'])\n",
        "X_train=np.array(X_train.values.tolist())\n",
        "X_test=np.array(X_test.values.tolist())\n",
        "y_train=np.array(y_train.values.tolist())\n",
        "y_test=np.array(y_test.values.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_IrvqFGyyB7",
        "colab_type": "text"
      },
      "source": [
        "## 6. Modeling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-k5VW8byyB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PlotLosses(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        \n",
        "        self.fig = plt.figure()\n",
        "        \n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        \n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.i)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.i += 1\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        plt.plot(self.x, self.losses, label=\"loss\")\n",
        "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
        "        plt.legend()\n",
        "#         print('Loss=',logs.get('loss'),'val_loss=',logs.get('val_loss'),'acc=',logs.get('acc'),'val_acc=',logs.get('val_acc'))\n",
        "        plt.show();\n",
        "plot_losses = PlotLosses() \n",
        "\n",
        "def save_model(model,save_name):\n",
        "    with open(save_name,'w+') as f:\n",
        "        f.write(model.to_json())\n",
        "    model.save_weights(save_name+'.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcehm9otyyB_",
        "colab_type": "code",
        "outputId": "622a6d93-09ce-44ff-fcac-76d9cf40a54f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "tokenizer=pipeline.named_steps['tokenizer']\n",
        "max_length=tokenizer.max_length\n",
        "vocab_size=tokenizer.vocab_size\n",
        "embeding_dim=50\n",
        "num_classes=y_train[0].shape[0]\n",
        "model=Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size,output_dim=embeding_dim,input_length=max_length))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'] )\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 50)           2295550   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                510       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 77        \n",
            "=================================================================\n",
            "Total params: 2,296,137\n",
            "Trainable params: 2,296,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPdk4nYtyyCC",
        "colab_type": "text"
      },
      "source": [
        "## 7. Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VCSQAjDayyCD",
        "colab_type": "code",
        "outputId": "385cc2e6-6f5e-4b1a-88e7-c0b3f42e0c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "model.fit(X_train,y_train,epochs=4,batch_size=10,verbose=0,validation_split=0.2,callbacks=[plot_losses])\n",
        "save_model(model,'model')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3zS+c6kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYyIeO4ayyCI",
        "colab_type": "text"
      },
      "source": [
        "## 8. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaST3joGyyCK",
        "colab_type": "code",
        "outputId": "08f2c1f3-5489-4baf-fa50-b597a75b2804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# load json and create model\n",
        "json_file = open('model', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "accuracy: 92.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C43lr-20390X",
        "colab_type": "text"
      },
      "source": [
        "## 9. Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6mVmtvs4Vy2",
        "colab_type": "code",
        "outputId": "8d62d2f8-c38c-4a7b-f4fe-c69ff1c4dc97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "vocab_size=pipeline.named_steps['tokenizer'].vocab_size\n",
        "max_length=pipeline.named_steps['tokenizer'].max_length\n",
        "label_encoder=pipeline.named_steps['one-hot-encoder'].label_encoder\n",
        "tokenizer=pipeline.named_steps['tokenizer'].tokenizer\n",
        "max_length=pipeline.named_steps['tokenizer'].max_length\n",
        "\n",
        "\n",
        "x=['large explosion at a texas fertilizer plant...multiple injuries reported...local hospital told to expect up to 100 patients: via ap']\n",
        "\n",
        "x_seq=tokenizer.texts_to_sequences(x)[0]\n",
        "x_pad=tf.keras.preprocessing.sequence.pad_sequences([x_seq],maxlen=max_length ,padding='post')[0]\n",
        "x_pad=np.array(x_pad)\n",
        "x_pad=x_pad.reshape(1,100)\n",
        "x_pad.shape\n",
        "predict=loaded_model.predict_classes(x_pad)\n",
        "score=max(loaded_model.predict(x_pad)[0])\n",
        "print(predict)\n",
        "print(label_encoder.inverse_transform(predict))\n",
        "print('score',score)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2]\n",
            "['explosion']\n",
            "score 0.99969137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEAJgDt7g49Z",
        "colab_type": "text"
      },
      "source": [
        "## 10. Hyperparameters Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzIEbJfJg6TG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(dropout, dense_size, vocab_size, embedding_dim, maxlen):\n",
        "    model=Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size,output_dim=embeding_dim,input_length=max_length))\n",
        "    model.add(GlobalMaxPool1D())\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(dense_size,activation='relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(num_classes,activation='softmax'))\n",
        "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmj52DYihwvT",
        "colab_type": "code",
        "outputId": "c833743c-ca8d-4572-bd48-c0390cbbfcf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "  \n",
        "# Main settings\n",
        "epochs = 5\n",
        "embedding_dim = 50\n",
        "maxlen = 100\n",
        "vocab_size=10000\n",
        "output_file = 'output.txt'\n",
        "#  dropout=[.1, 0.2, 0.3,0.4,0.5],\n",
        "dense_size=[10, 50,100],\n",
        "\n",
        "# Parameter grid for grid search\n",
        "param_grid = dict(dropout=[0.1],\n",
        "                  dense_size=[10, 50,100],\n",
        "                  vocab_size=[vocab_size],\n",
        "                  embedding_dim=[embedding_dim],\n",
        "                  maxlen=[maxlen])\n",
        "model = KerasClassifier(build_fn=create_model,\n",
        "                        epochs=epochs, batch_size=10,\n",
        "                        verbose=False)\n",
        "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
        "                          cv=4, verbose=1, n_iter=5 ,n_jobs=2)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate testing set\n",
        "test_accuracy = grid.score(X_test, y_test)\n",
        "\n",
        "# Save and evaluate results\n",
        "with open(output_file, 'a') as f:\n",
        "    s = ('Best Accuracy : '\n",
        "         '{:.4f}\\n{}\\nTest Accuracy : {:.4f}\\n\\n')\n",
        "    output_string = s.format(\n",
        "        grid_result.best_score_,\n",
        "        grid_result.best_params_,\n",
        "        test_accuracy)\n",
        "    print(output_string)\n",
        "    f.write(output_string)  \n",
        "print('Done')    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  12 out of  12 | elapsed: 12.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best Accuracy : 0.9266\n",
            "{'vocab_size': 10000, 'maxlen': 100, 'embedding_dim': 50, 'dropout': 0.1, 'dense_size': 10}\n",
            "Test Accuracy : 0.9308\n",
            "\n",
            "\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W02P5TXJ37YG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}