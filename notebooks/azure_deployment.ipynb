{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import requests\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import LocalWebservice\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import re\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import model_from_json ,load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from azureml.core.model import Model\n",
    "from azureml.contrib.services.aml_response import AMLResponse\n",
    "\n",
    "\n",
    "MAX_TWEET_LENGTH = 100\n",
    "MIN_PREDICTION_SCORE = 0.8\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model, tokenizer, label_encoder, classifier\n",
    "    model_path =Model.get_model_path('disaster-watch-model-keras',version=1)\n",
    "    model = load_model(model_path , custom_objects={\"adam\": tf.keras.optimizers.Adam})\n",
    "    model_path = Model.get_model_path('disaster-watch-tokenizer', version=1)\n",
    "    tokenizer = joblib.load(model_path)\n",
    "    model_path = Model.get_model_path('disaster-watch-label-encoder', version=1)\n",
    "    label_encoder = joblib.load(model_path)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    classifier = TweeterClassifier(tokenizer, label_encoder, model)\n",
    "\n",
    "\n",
    "def run(request):\n",
    "    payload = json.loads(request)\n",
    "    min_score = payload.get('minScore', MIN_PREDICTION_SCORE)\n",
    "    prediction = classifier.predict(payload['tweet'], min_score)\n",
    "    response = AMLResponse(prediction, 200)\n",
    "    response.headers['Access-Control-Allow-Origin'] = '*'\n",
    "    return prediction\n",
    "\n",
    "\n",
    "class TweeterClassifier:\n",
    "    \"\"\"Classification class that loads the saved Tensorflow 2.0 model and weights\n",
    "       and classifies the disaster related  tweets.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer, label_encoder, model):\n",
    "        # Load pre-processing\n",
    "        self.MAX_TWEET_LENGTH = 100\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_encoder = label_encoder\n",
    "        self.model = model\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    def predict(self, tweet, min_score):\n",
    "        tweet = self._sanitize(tweet)\n",
    "        x = [tweet]\n",
    "        x_seq = self.tokenizer.texts_to_sequences(x)[0]\n",
    "        x_pad = keras.preprocessing.sequence.pad_sequences([x_seq], maxlen=self.MAX_TWEET_LENGTH, padding='post')[0]\n",
    "        x_pad = np.array(x_pad)\n",
    "        x_pad = x_pad.reshape(1, self.MAX_TWEET_LENGTH)\n",
    "        prediction_class = self.model.predict_classes(x_pad)\n",
    "        prediction_score = max(self.model.predict(x_pad)[0])\n",
    "        prediction_category = self.label_encoder.inverse_transform(prediction_class)[0]\n",
    "        if prediction_score < min_score:\n",
    "            prediction_category = 'unrelated'\n",
    "        return {'category': prediction_category, 'score': str(prediction_score), 'tweet': tweet}\n",
    "\n",
    "    def _sanitize(self, tweet):\n",
    "        tweet = tweet.lower()\n",
    "        tweet = tweet.replace('@', '')\n",
    "        tweet = tweet.replace('#', '')\n",
    "        tweet = tweet.replace('.', '')\n",
    "        tweet = tweet.replace(',', '')\n",
    "        tweet = re.sub(r'http\\S+', '', tweet)\n",
    "        for word in ['pakistan', 'nepal', 'chile', 'texas', 'boston', 'california', 'alberta', 'calgary', 'queensland',\n",
    "                     'india', 'oklahoma']:\n",
    "            tweet = tweet.replace(word, '')\n",
    "        return tweet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialze():\n",
    "    subscription_id = \"979884b7-8494-4a3d-abd7-e9e63d1f5d90\"  \n",
    "    resource_group = \"azure-ai-hackathon-ml\"  \n",
    "    workspace_name = \"azure-ai-hackathon-ws\"  \n",
    "    workspace_region = \"West US 2\"  \n",
    "   \n",
    "    interactive_auth = InteractiveLoginAuthentication()\n",
    "    ws = Workspace.get(\n",
    "        name=workspace_name,\n",
    "        subscription_id=subscription_id,\n",
    "        resource_group=resource_group,\n",
    "        auth=interactive_auth\n",
    "    )\n",
    "    return ws\n",
    "\n",
    "def get_environment():\n",
    "    environment = Environment(\"LocalDeploy\")\n",
    "    conda_dep = CondaDependencies()\n",
    "    conda_dep.add_pip_package(\"h5py\")\n",
    "    conda_dep.add_pip_package(\"joblib\")\n",
    "    conda_dep.add_pip_package(\"numpy\")\n",
    "    conda_dep.add_pip_package(\"pandas\")\n",
    "    conda_dep.add_pip_package(\"python-dateutil\")\n",
    "    conda_dep.add_pip_package(\"pytz\")\n",
    "    conda_dep.add_pip_package(\"scikit-learn\")\n",
    "    conda_dep.add_pip_package(\"tensorflow\")\n",
    "    conda_dep.add_pip_package(\"azureml-core\")\n",
    "    conda_dep.add_pip_package(\"azureml-contrib-services\")\n",
    "\n",
    "    environment.python.conda_dependencies = conda_dep\n",
    "    return environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = initialze()\n",
    "environment = get_environment()\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\",\n",
    "                                   environment=environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_local():\n",
    "    deployment_config = LocalWebservice.deploy_configuration()\n",
    "    model = Model(name='disaster-watch-model-keras', workspace=ws, version=1)\n",
    "    tokenizer = Model(name='disaster-watch-tokenizer', workspace=ws, version=1)\n",
    "    label_encoder = Model(name='disaster-watch-label-encoder', workspace=ws, version=1)\n",
    "    local_service = Model.deploy(ws, \"local-deploy\", [model, tokenizer, label_encoder], inference_config, deployment_config)\n",
    "    local_service.wait_for_deployment()\n",
    "\n",
    "def deploy_to_cloud():\n",
    "    deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "    model = Model(name='disaster-watch-model-keras', workspace=ws, version=1)\n",
    "    tokenizer = Model(name='disaster-watch-tokenizer', workspace=ws, version=1)\n",
    "    label_encoder = Model(name='disaster-watch-label-encoder', workspace=ws, version=1)\n",
    "    aci_service_name = 'disaster-watch-service'\n",
    "    try:\n",
    "        # deleting existing aci if any\n",
    "        service = Webservice(ws, name=aci_service_name)\n",
    "        if service:\n",
    "            service.delete()\n",
    "    except WebserviceException as e:\n",
    "        print()\n",
    "\n",
    "    service = Model.deploy(ws, aci_service_name, [model, tokenizer, label_encoder], inference_config, deployment_config)\n",
    "\n",
    "    service.wait_for_deployment(True)\n",
    "    print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model disaster-watch-model-keras:1 to /tmp/azureml_iyv8erkk/disaster-watch-model-keras/1\n",
      "Downloading model disaster-watch-tokenizer:1 to /tmp/azureml_iyv8erkk/disaster-watch-tokenizer/1\n",
      "Downloading model disaster-watch-label-encoder:1 to /tmp/azureml_iyv8erkk/disaster-watch-label-encoder/1\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry azureaihacka6d64e0ee.azurecr.io\n",
      "Logging into Docker registry azureaihacka6d64e0ee.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM azureaihacka6d64e0ee.azurecr.io/azureml/azureml_1f1c28ac8a28fb742de605694473acfe\n",
      " ---> 237daad85902\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 15791ac781ab\n",
      "Step 3/5 : COPY model_config_map.json /var/azureml-app/model_config_map.json\n",
      " ---> 0a539817b72c\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmp5_8gfis0.py' /var/azureml-app/main.py\n",
      " ---> Running in f8fd7e33182b\n",
      " ---> b1e815a50ff1\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in d4bc318e91a7\n",
      " ---> 1a3e7a27b081\n",
      "Successfully built 1a3e7a27b081\n",
      "Successfully tagged local-deploy:latest\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:32768\n"
     ]
    }
   ],
   "source": [
    "deploy_local()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy th Model as Webservice on Azure Container Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...........................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "deploy_to_cloud()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the service locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'explosion',\n",
       " 'score': '0.96989554',\n",
       " 'tweet': 'large explosion at a  fertilizer plantmultiple injuries reportedlocal hospital told to expect up to 100 patients: via ap'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=requests.post('http://localhost:32768/score',json={\n",
    "    'tweet':'large explosion at a texas fertilizer plant...multiple injuries reported...local hospital told to expect up to 100 patients: via ap'\n",
    "})\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
